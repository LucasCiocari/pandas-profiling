{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_profiling\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "require.config({\n",
       "paths: {\n",
       "d3: \"https://d3js.org/d3.v5.min\",\n",
       "}\n",
       "});\n",
       "\n",
       "require([\"d3\"], function(d3) {\n",
       "window.d3 = d3;\n",
       "});\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "require.config({\n",
    "paths: {\n",
    "d3: \"https://d3js.org/d3.v5.min\",\n",
    "}\n",
    "});\n",
    "\n",
    "require([\"d3\"], function(d3) {\n",
    "window.d3 = d3;\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"symboling\", \"normalized-losses\", \"make\", \"fuel-type\", \"aspiration\", \"num-of-doors\", \"body-style\", \"drive-wheels\", \"engine-location\", \"wheel-base\", \"length\", \"width\", \"height\",\n",
    "           \"curb-weight\", \"engine-type\", \"num-of-cylinders\", \"engine-size\", \"fuel-system\", \"bore\", \"stroke\", \"compression-ratio\", \"horsepower\", \"peak-rpm\", \"city-mpg\", \"highway-mpg\", \"price\"]\n",
    "\n",
    "df = pd.read_csv('imports-85.data', names=columns)\n",
    "\n",
    "for col in df.columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors='ignore')\n",
    "\n",
    "df.replace(to_replace=[\"na\", \"?\", np.nan, \"missing\", \"not available\",\"n/a\", \"missing value\"], value=np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_profiling.ProfileReport(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"class\", \"age\", \"menopause\", \"tumor-size\", \"inv-nodes\", \n",
    "           \"node-caps\", \"deg-malig\", \"breast\", \"breast-quad\", \"irradiat\"]\n",
    "\n",
    "df = pd.read_csv('breast-cancer.data', names=columns)\n",
    "\n",
    "df['deg-malig'].replace(to_replace={1: 'one', 2:'two', 3:'three'}, inplace=True)\n",
    "\n",
    "df.replace(to_replace=[\"na\", \"?\", np.nan, \"missing\", \"not available\",\"n/a\", \"missing value\"], value=np.nan, inplace=True)\n",
    "\n",
    "\n",
    "pandas_profiling.ProfileReport(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"class\",\"age\",\"sex\",\"histologic-type\",\"degree-of-diffe\",\"bone\",\"bone-marrow\",\"lung\",\"pleura\",\"peritoneum\",\"liver\",\"brain\",\"skin\",\"neck\",\"supraclavicular\",\"axillar\",\"mediastinum\",\"abdominal\"]\n",
    "\n",
    "df = pd.read_csv('primary-tumor.data', names=columns)\n",
    "\n",
    "df.replace(to_replace=[\"na\", \"?\", np.nan, \"missing\", \"not available\",\"n/a\", \"missing value\"], value=np.nan, inplace=True)\n",
    "\n",
    "for col in df.columns:\n",
    "    df[col] = pd.to_numeric(df[col], errors='ignore')\n",
    "\n",
    "df[\"class\"].replace(to_replace= {1:\"lung\", 2:\"head & neck\", 3:\"esophasus\", 4:\"thyroid\", 5:\"stomach\", 6:\"duoden & sm.int\", 7:\"colon\", 8:\"rectum\", 9:\"anus\", 10:\"salivary glands\", 11:\"pancreas\", 12:\"gallblader\", 13:\"liver\", 14:\"kidney\", 15:\"bladder\", 16:\"testis\", 17:\"prostate\", 18:\"ovary\", 19:\"corpus uteri\", 20: \"cervix uteri\", 21:\"vagina\", 22:\"breast\"}, inplace=True)\n",
    "\n",
    "df[\"age\"].replace(to_replace ={1:\"<30\",2:\"30-59\",3:\">60\"}, inplace=True)\n",
    "df[\"sex\"].replace(to_replace ={1:\"male\",2:\"female\"}, inplace=True)\n",
    "df[\"histologic-type\"].replace(to_replace ={1.0:\"epidermoid\",2.0:\"adeno\", 3.0:\"anaplastic\"}, inplace=True)\n",
    "df[\"degree-of-diffe\"].replace(to_replace={1:\"well\", 2:\"fairly\", 3:\"poorly\"}, inplace=True)\n",
    "df[\"bone\"].replace(to_replace={1:\"yes\", 2:\"no\"}, inplace=True)\n",
    "df[\"bone-marrow\"].replace(to_replace={1:\"yes\", 2:\"no\"}, inplace=True)\n",
    "df[\"lung\"].replace(to_replace={1:\"yes\", 2:\"no\"}, inplace=True)\n",
    "df[\"pleura\"].replace(to_replace={1:\"yes\", 2:\"no\"}, inplace=True)\n",
    "df[\"peritoneum\"].replace(to_replace={1:\"yes\", 2:\"no\"}, inplace=True)\n",
    "df[\"liver\"].replace(to_replace={1:\"yes\", 2:\"no\"}, inplace=True)\n",
    "df[\"brain\"].replace(to_replace={1:\"yes\", 2:\"no\"}, inplace=True)\n",
    "df[\"skin\"].replace(to_replace={1:\"yes\", 2:\"no\"}, inplace=True)\n",
    "df[\"neck\"].replace(to_replace={1:\"yes\", 2:\"no\"}, inplace=True)\n",
    "df[\"supraclavicular\"].replace(to_replace={1:\"yes\", 2:\"no\"}, inplace=True)\n",
    "df[\"axillar\"].replace(to_replace={1:\"yes\", 2:\"no\"}, inplace=True)\n",
    "df[\"mediastinum\"].replace(to_replace={1:\"yes\", 2:\"no\"}, inplace=True)\n",
    "df[\"abdominal\"].replace(to_replace={1:\"yes\", 2:\"no\"}, inplace=True)\n",
    "df[\"histologic-type\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_profiling.ProfileReport(df).to_file(\"../../../../Desktop/example.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'porta': ['duas', 'quatro', 'duas', 'quatro', 'quatro', 'duas', 'duas'],\n",
    "                    'combustivel': ['gas', 'diesel', 'gas', 'gas', 'diesel', 'diesel', 'gas'],\n",
    "                    'body-style': ['sedan', 'hatch', 'hatch', 'sedan', 'sedan', 'hatch', 'hatch']\n",
    "                    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_data_format(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_data(df):\n",
    "    count = []\n",
    "    considered_cols = []\n",
    "    last_index = 0\n",
    "    keys = {}\n",
    "\n",
    "    df.replace(to_replace=[\"na\", \"?\", np.nan, \"missing\", \"not available\",\n",
    "                           \"n/a\", \"missing value\"], value=np.nan, inplace=True)\n",
    "\n",
    "    for col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='ignore')\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == \"object\":\n",
    "            df[col].replace(to_replace=[\"na\", \"?\", np.nan, \"missing\", \"not available\",\n",
    "                                        \"n/a\", \"missing value\"], value=\"missing value\", inplace=True)\n",
    "            if df[col].unique().size < 25:\n",
    "                considered_cols.append(col)\n",
    "                keys[col] = {\"values\": df[col].unique().tolist(\n",
    "                ), \"start_i\": last_index, \"end_i\": last_index + df[col].unique().size}\n",
    "                last_index = last_index + df[col].unique().size\n",
    "                for item in df[col].unique():\n",
    "                    count.append([col, item])\n",
    "    data_array = np.zeros((len(count), len(count)))\n",
    "\n",
    "    for row in range(df.shape[0]):\n",
    "        for col in range(df.shape[1]):\n",
    "            for i in range(col+1, df.shape[1]):\n",
    "                if df.columns[col] in considered_cols and df.columns[i] in considered_cols:\n",
    "                    data_array[count.index([df.columns[col], df.iloc[row, col]]), count.index(\n",
    "                        [df.columns[i], df.iloc[row, i]])] += 1\n",
    "\n",
    "    data_array += np.transpose(data_array)\n",
    "    return keys, data_array.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_data_format(df_orig):\n",
    "    metadata = []\n",
    "    df = df_orig\n",
    "    df.replace(to_replace=[\"na\", \"?\", np.nan, \"missing\", \"not available\",\n",
    "                           \"n/a\", \"missing value\"], value=np.nan, inplace=True)\n",
    "\n",
    "    for col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='ignore')\n",
    "\n",
    "    for idx, col in enumerate(df.columns):\n",
    "        helper = {}\n",
    "        key = col\n",
    "        if len(key) > 15:\n",
    "            key = col[:15]\n",
    "\n",
    "        helper['ascend'] = 0\n",
    "        helper['name'] = key\n",
    "        if(df.dtypes[col] == \"object\"):\n",
    "            df[col].replace(to_replace=[\"na\", \"?\", np.nan, \"missing\", \"not available\",\n",
    "                                        \"n/a\", \"missing value\"], value=\"missing value\", inplace=True)\n",
    "            helper['datatype'] = 'string'\n",
    "            helper['values'] = df[col].unique().tolist()\n",
    "        elif(df.dtypes[col] == \"int64\"):\n",
    "            helper['datatype'] = 'int'\n",
    "            helper['min_val'] = df[col].min()\n",
    "            helper['max_val'] = df[col].max()\n",
    "        elif(df.dtypes[col] == \"float64\"):\n",
    "            helper['datatype'] = 'float'\n",
    "            helper['min_val'] = df[col].min()\n",
    "            helper['max_val'] = df[col].max()\n",
    "        metadata.append(helper)\n",
    "\n",
    "    df.replace(to_replace=[\"na\", \"?\", np.nan, \"missing\", \"not available\",\n",
    "                           \"n/a\", \"missing value\"], value=\"missing value\", inplace=True)\n",
    "    data_array = []\n",
    "    for row in range(df.shape[0]):\n",
    "        aux = []\n",
    "        for col in range(df.shape[1]):\n",
    "            aux.append(df.iloc[row, col])\n",
    "        data_array.append(aux)\n",
    "    return metadata, data_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['TP_SEXO', 'TP_COR_RACA', 'TP_NACIONALIDADE', 'TP_ST_CONCLUSAO', 'TP_ESCOLA', 'TP_DEPENDENCIA_ADM_ESC', 'TP_ENSINO', \n",
    "          'IN_TREINEIRO', 'TP_LOCALIZACAO_ESC', \"TP_PRESENCA_CN\", \n",
    "          \"TP_PRESENCA_CH\", \"TP_PRESENCA_LC\", \"TP_PRESENCA_MT\", \"NU_NOTA_CN\", 'NU_NOTA_CH', \n",
    "          'NU_NOTA_LC', 'NU_NOTA_MT', 'TP_LINGUA', 'TP_STATUS_REDACAO', 'NU_NOTA_REDACAO', 'Q006', 'Q026']\n",
    "df = pd.read_csv('C:\\\\Users\\\\Lucas\\\\Downloads\\\\microdados_enem2018\\\\DADOS\\\\MICRODADOS_ENEM_2018.csv', \n",
    "                 sep=';', encoding='latin-1', skipinitialspace=True, usecols=fields)\n",
    "\n",
    "df.drop(df[\n",
    "    (df['TP_ST_CONCLUSAO'] != 2) | \n",
    "    (df['TP_ENSINO'] != 1) | \n",
    "    (df['IN_TREINEIRO'] == 1) |\n",
    "    (df['TP_PRESENCA_CN'] != 1) |\n",
    "    (df['TP_PRESENCA_CH'] != 1) |\n",
    "    (df['TP_PRESENCA_LC'] != 1) |\n",
    "    (df['TP_PRESENCA_MT'] != 1) |\n",
    "    (df['TP_STATUS_REDACAO'] != 1) |\n",
    "    (df['Q026'] != 'B')\n",
    "    ].index, inplace=True)\n",
    "\n",
    "df['NOTA_FINAL'] = list(map(lambda a,b,c,d, e: (a + b + c + d + e)/5, df['NU_NOTA_CN'], df['NU_NOTA_CH'], df['NU_NOTA_LC'], df['NU_NOTA_MT'], df['NU_NOTA_REDACAO']))\n",
    "df[\"TP_COR_RACA\"].replace(to_replace ={0:np.nan,1:\"Branca\",2:'Preta',3:\"Parda\", 4:'Amarela', 5:'Indígena'}, inplace=True)\n",
    "df[\"TP_NACIONALIDADE\"].replace(to_replace ={0:np.nan,1:\"Brasileiro(a)\",2:'Brasileiro(a) Naturalizado(a)',3:\"Estrangeiro(a)\", 4:'Brasileiro(a) Nato(a), nascido(a) no exterior'}, inplace=True)\n",
    "df.drop(columns=['TP_ST_CONCLUSAO', 'TP_ENSINO', 'IN_TREINEIRO', 'TP_PRESENCA_CH', 'TP_PRESENCA_LC', 'TP_PRESENCA_MT', 'TP_PRESENCA_CN', 'TP_STATUS_REDACAO', 'Q026', 'NU_NOTA_CN', 'NU_NOTA_CH', 'NU_NOTA_LC', 'NU_NOTA_MT', 'NU_NOTA_REDACAO'], inplace=True)\n",
    "df[\"TP_ESCOLA\"].replace(to_replace ={1:np.nan, 2:'Pública', 3:\"Privada\", 4:'Exterior'}, inplace=True)\n",
    "df[\"TP_LOCALIZACAO_ESC\"].replace(to_replace ={1:\"Urbana\", 2:'Rural'}, inplace=True)\n",
    "df[\"TP_LINGUA\"].replace(to_replace ={0:\"Inglês\", 1:'Espanhol'}, inplace=True)\n",
    "df['Q006'].replace(to_replace = {'A' :'Nenhuma renda.','B' : 'Até RS 954,00.',\n",
    "                                 'C' :'De RS 954,01 até RS 1.431,00.','D' : 'De RS 1.431,01 até RS 1.908,00.',\n",
    "                                 'E' :'De RS 1.908,01 até RS 2.385,00.','F' :'De RS 2.385,01 até RS 2.862,00.',\n",
    "                                 'G' :'De RS 2.862,01 até RS 3.816,00.','H' :'De RS 3.816,01 até RS 4.770,00.',\n",
    "                                 'I' :'De RS 4.770,01 até RS 5.724,00.','J' :'De RS 5.724,01 até RS 6.678,00.',\n",
    "                                 'K' :'De RS 6.678,01 até RS 7.632,00.','L' :'De RS 7.632,01 até RS 8.586,00.',\n",
    "                                 'M' :'De RS 8.586,01 até RS 9.540,00.','N' :'De RS 9.540,01 até RS 11.448,00.',\n",
    "                                 'O' :'De RS 11.448,01 até RS 14.310,00.','P' :'De RS 14.310,01 até RS 19.080,00.',\n",
    "                                 'Q' :'Mais de RS 19.080,00.'}, inplace=True)\n",
    "df['TP_DEPENDENCIA_ADM_ESC'].replace(to_replace={1:'Federal', 2:'Estadual', 3:'Municipal', 4:'Privada'}, inplace=True)\n",
    "\n",
    "q1,q2,q3 = df['NOTA_FINAL'].quantile([0.25,0.5,0.75])\n",
    "\n",
    "\n",
    "df['NOTA_FINAL'] = pd.to_numeric(df['NOTA_FINAL'], errors='ignore')\n",
    "\n",
    "def quartile_definition(val):\n",
    "    if type(val) != 'str':\n",
    "        if val < q1:\n",
    "            return '1st quartile'\n",
    "        if val < q2:\n",
    "            return '2nd quartile'\n",
    "        if val < q3:\n",
    "            return '3rd quartile'\n",
    "\n",
    "df['NOTA_FINAL'] = df['NOTA_FINAL'].map(quartile_definition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8          1st quartile\n",
       "16         3rd quartile\n",
       "26         3rd quartile\n",
       "29         1st quartile\n",
       "39         2nd quartile\n",
       "               ...     \n",
       "5513730    1st quartile\n",
       "5513735    1st quartile\n",
       "5513736    1st quartile\n",
       "5513743    1st quartile\n",
       "5513745    2nd quartile\n",
       "Name: NOTA_FINAL, Length: 1154924, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['NOTA_FINAL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from jinja2 import Environment, FileSystemLoader\n",
    "\n",
    "\n",
    "def build_data(df):\n",
    "    count = []\n",
    "    considered_cols = []\n",
    "    last_index = 0\n",
    "    keys = {}\n",
    "\n",
    "    df.replace(to_replace=[\"na\", \"?\", np.nan, \"missing\", \"not available\",\n",
    "                           \"n/a\", \"missing value\"], value=np.nan, inplace=True)\n",
    "\n",
    "    for col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='ignore')\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == \"object\":\n",
    "            df[col].replace(to_replace=[\"na\", \"?\", np.nan, \"missing\", \"not available\",\n",
    "                                        \"n/a\", \"missing value\"], value=\"missing value\", inplace=True)\n",
    "            if df[col].unique().size < 25:\n",
    "                considered_cols.append(col)\n",
    "                keys[col] = {\"values\": df[col].unique().tolist(\n",
    "                ), \"start_i\": last_index, \"end_i\": last_index + df[col].unique().size}\n",
    "                last_index = last_index + df[col].unique().size\n",
    "                for item in df[col].unique():\n",
    "                    count.append([col, item])\n",
    "    data_array = np.zeros((len(count), len(count)))\n",
    "\n",
    "    for row in range(df.shape[0]):\n",
    "        for col in range(df.shape[1]):\n",
    "            for i in range(col+1, df.shape[1]):\n",
    "                if df.columns[col] in considered_cols and df.columns[i] in considered_cols:\n",
    "                    data_array[count.index([df.columns[col], df.iloc[row, col]]), count.index(\n",
    "                        [df.columns[i], df.iloc[row, i]])] += 1\n",
    "\n",
    "    data_array += np.transpose(data_array)\n",
    "    return keys, data_array.tolist()\n",
    "\n",
    "\n",
    "# df = pd.DataFrame({'porta': ['duas', 'quatro', 'duas', 'quatro', 'quatro', 'duas', 'duas'],\n",
    "#                    'combustivel': ['gas', 'diesel', 'gas', 'gas', 'diesel', 'diesel', 'gas'],\n",
    "#                    'body-style': ['sedan', 'hatch', 'hatch', 'sedan', 'sedan', 'hatch', 'hatch']\n",
    "#                    })\n",
    "\n",
    "# columns = [\"symboling\", \"normalized-losses\", \"make\", \"fuel-type\", \"aspiration\", \"num-of-doors\", \"body-style\", \"drive-wheels\", \"engine-location\", \"wheel-base\", \"length\", \"width\", \"height\",\n",
    "#            \"curb-weight\", \"engine-type\", \"num-of-cylinders\", \"engine-size\", \"fuel-system\", \"bore\", \"stroke\", \"compression-ratio\", \"horsepower\", \"peak-rpm\", \"city-mpg\", \"highway-mpg\", \"price\"]\n",
    "\n",
    "# df = pd.read_csv('imports-85.data', names=columns)\n",
    "\n",
    "\n",
    "file_loader = FileSystemLoader(\"templates\")\n",
    "env = Environment(loader=file_loader)\n",
    "\n",
    "template = env.get_template(\"bid.html\")\n",
    "\n",
    "keys, data_array = build_data(df)\n",
    "\n",
    "output = template.render(data=keys, full_matrix=data_array)\n",
    "\n",
    "with open(\"result.html\", \"w\") as result_file:\n",
    "    result_file.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
